#!/usr/bin/env python3
"""
YOLOv8åˆ†å‰²æ¨¡åž‹æŽ¨ç†è„šæœ¬
åŠŸèƒ½ï¼šå¯¹è¾“å…¥å›¾åƒè¿›è¡ŒæŸä¼¤æ£€æµ‹å’Œåˆ†å‰²ï¼Œç”¨ä¸­æ–‡æ ‡ç­¾æ ‡æ³¨ç»“æžœ
ä½¿ç”¨æ–¹æ³•ï¼špython inference.py --image å›¾ç‰‡è·¯å¾„
"""

import argparse
import cv2
import numpy as np
import os
from pathlib import Path
from ultralytics import YOLO
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont

class DamageDetector:
    def __init__(self, model_path, output_dir="inference_results"):
        """
        åˆå§‹åŒ–æŸä¼¤æ£€æµ‹å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡åž‹æƒé‡è·¯å¾„
            output_dir: ç»“æžœä¿å­˜ç›®å½•
        """
        # åŠ è½½æ¨¡åž‹
        self.model = YOLO(model_path)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ä¸­æ–‡æ ‡ç­¾æ˜ å°„
        self.chinese_labels = {
            0: "å®Œå¥½",
            1: "è½»åº¦æŸæ¯", 
            2: "é‡åº¦æŸæ¯",
            3: "å€’å¡Œ",
            4: "çŠ¶å†µæœªçŸ¥"
        }
        
        # é¢œè‰²æ˜ å°„ï¼ˆBGRæ ¼å¼ï¼‰
        self.color_map = {
            0: (0, 255, 0),      # ç»¿è‰² - å®Œå¥½
            1: (255, 255, 0),    # é’è‰² - è½»åº¦æŸæ¯
            2: (0, 165, 255),    # æ©™è‰² - é‡åº¦æŸæ¯  
            3: (0, 0, 255),      # çº¢è‰² - å€’å¡Œ
            4: (128, 128, 128)   # ç°è‰² - çŠ¶å†µæœªçŸ¥
        }
        
        print(f"âœ… æ¨¡åž‹åŠ è½½æˆåŠŸ: {model_path}")
        print(f"âœ… ç»“æžœå°†ä¿å­˜åˆ°: {self.output_dir.absolute()}")
    
    def load_chinese_font(self, font_size=20):
        """
        å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
        """
        # å°è¯•å¤šç§å¸¸è§ä¸­æ–‡å­—ä½“è·¯å¾„
        font_paths = [
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",  # Linux
            "/System/Library/Fonts/PingFang.ttc",               # macOS
            "C:/Windows/Fonts/simhei.ttf",                      # Windows
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",  # Linuxå¤‡ç”¨
        ]
        
        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    return ImageFont.truetype(font_path, font_size)
                except:
                    continue
        
        # å¦‚æžœæ‰¾ä¸åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½ä¸æ”¯æŒä¸­æ–‡ï¼‰
        print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ˜¾ç¤ºä¸­æ–‡ï¼‰")
        return ImageFont.load_default()
    
    def process_image(self, image_path, conf_threshold=0.25):
        """
        å¤„ç†å•å¼ å›¾åƒ
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            result_image: å¤„ç†åŽçš„å›¾åƒè·¯å¾„
        """
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {image_path}")
        
        print(f"ðŸ” å¼€å§‹å¤„ç†å›¾åƒ: {image_path}")
        
        # ä½¿ç”¨YOLOæ¨¡åž‹è¿›è¡ŒæŽ¨ç†
        results = self.model.predict(
            source=image_path,
            conf=conf_threshold,
            imgsz=1024,  # ä½¿ç”¨è®­ç»ƒæ—¶çš„å°ºå¯¸
            save=False,   # æˆ‘ä»¬ä¸ä½¿ç”¨å†…ç½®ä¿å­˜åŠŸèƒ½ï¼Œè‡ªå·±æŽ§åˆ¶è¾“å‡º
            verbose=False # å‡å°‘è¾“å‡º
        )
        
        if len(results) == 0:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
            return self._save_no_detection_result(image_path)
        
        # èŽ·å–ç¬¬ä¸€ä¸ªç»“æžœï¼ˆå•å¼ å›¾åƒï¼‰
        result = results[0]
        
        if result.masks is None or len(result.boxes) == 0:
            print("âš ï¸ æœªæ£€æµ‹åˆ°åˆ†å‰²ç›®æ ‡")
            return self._save_no_detection_result(image_path)
        
        # è¯»å–åŽŸå§‹å›¾åƒ
        original_image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
        
        # ä½¿ç”¨PILè¿›è¡Œå›¾åƒå¤„ç†ï¼ˆæ›´å¥½çš„æ–‡æœ¬æ”¯æŒï¼‰
        pil_image = Image.fromarray(image_rgb)
        draw = ImageDraw.Draw(pil_image)
        font = self.load_chinese_font(24)
        
        # èŽ·å–æ£€æµ‹ä¿¡æ¯
        boxes = result.boxes
        masks = result.masks
        class_ids = boxes.cls.cpu().numpy().astype(int)
        confidences = boxes.conf.cpu().numpy()
        
        print(f"ðŸŽ¯ æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")
        
        # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹ç»“æžœ
        for i, (class_id, confidence, mask) in enumerate(zip(class_ids, confidences, masks.data)):
            # èŽ·å–ç±»åˆ«ä¿¡æ¯
            damage_type = int(class_id)
            chinese_label = self.chinese_labels.get(damage_type, "æœªçŸ¥")
            color = self.color_map.get(damage_type, (255, 255, 255))
            
            # å¤„ç†åˆ†å‰²æŽ©ç 
            mask_np = mask.cpu().numpy()
            mask_resized = cv2.resize(mask_np, (original_image.shape[1], original_image.shape[0]))
            
            # åˆ›å»ºå½©è‰²æŽ©ç 
            color_mask = np.zeros_like(original_image)
            color_mask[mask_resized > 0.5] = color[::-1]  # RGBè½¬BGR
            
            # å°†æŽ©ç å åŠ åˆ°åŽŸå›¾ï¼ˆé€æ˜Žåº¦æ··åˆï¼‰
            alpha = 0.3
            original_image = cv2.addWeighted(original_image, 1, color_mask, alpha, 0)
            
            # èŽ·å–è¾¹ç•Œæ¡†åæ ‡ï¼ˆç”¨äºŽæ”¾ç½®æ ‡ç­¾ï¼‰
            x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
            
            # åœ¨PILå›¾åƒä¸Šç»˜åˆ¶æ–‡æœ¬ï¼ˆæ›´å¥½çš„ä¸­æ–‡æ”¯æŒï¼‰
            label_text = f"{chinese_label} {confidence:.2f}"
            draw.text((x1, y1 - 30), label_text, fill=color, font=font)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
            
            print(f"  - ç›®æ ‡ {i+1}: {chinese_label} (ç½®ä¿¡åº¦: {confidence:.3f})")
        
        # è½¬æ¢å›žOpenCVæ ¼å¼å¹¶ä¿å­˜
        result_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        input_path = Path(image_path)
        output_filename = f"result_{input_path.stem}.png"
        output_path = self.output_dir / output_filename
        
        # ä¿å­˜ç»“æžœ
        cv2.imwrite(str(output_path), result_image)
        
        # åˆ›å»ºæ£€æµ‹ç»“æžœç»Ÿè®¡å›¾
        stats_image_path = self._create_statistics_chart(class_ids, confidences, output_path.stem)
        
        print(f"âœ… ç»“æžœå·²ä¿å­˜: {output_path}")
        print(f"ðŸ“Š ç»Ÿè®¡å›¾è¡¨: {stats_image_path}")
        
        return str(output_path), stats_image_path
    
    def _save_no_detection_result(self, image_path):
        """å¤„ç†æ— æ£€æµ‹ç»“æžœçš„æƒ…å†µ"""
        original_image = cv2.imread(image_path)
        
        # åœ¨å›¾åƒä¸Šæ·»åŠ "æœªæ£€æµ‹åˆ°ç›®æ ‡"çš„æ–‡æœ¬
        text = "æœªæ£€æµ‹åˆ°æŸä¼¤ç›®æ ‡"
        font_scale = 2
        thickness = 3
        color = (0, 0, 255)  # çº¢è‰²
        
        # èŽ·å–æ–‡æœ¬å°ºå¯¸
        (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
        
        # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆå±…ä¸­ï¼‰
        x = (original_image.shape[1] - text_width) // 2
        y = (original_image.shape[0] + text_height) // 2
        
        # æ·»åŠ æ–‡æœ¬
        cv2.putText(original_image, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)
        
        # ä¿å­˜ç»“æžœ
        input_path = Path(image_path)
        output_path = self.output_dir / f"no_detection_{input_path.stem}.png"
        cv2.imwrite(str(output_path), original_image)
        
        return str(output_path), None
    
    def _create_statistics_chart(self, class_ids, confidences, image_name):
        """åˆ›å»ºæ£€æµ‹ç»“æžœç»Ÿè®¡å›¾è¡¨"""
        # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°é‡
        unique, counts = np.unique(class_ids, return_counts=True)
        class_counts = dict(zip(unique, counts))
        
        # å‡†å¤‡æ•°æ®
        labels = [self.chinese_labels.get(i, "æœªçŸ¥") for i in unique]
        sizes = [class_counts.get(i, 0) for i in unique]
        colors = [tuple(c/255 for c in self.color_map[i][::-1]) for i in unique]  # è½¬æ¢é¢œè‰²æ ¼å¼
        
        # åˆ›å»ºé¥¼å›¾
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
        
        # é¥¼å›¾ - å„ç±»åˆ«æ•°é‡åˆ†å¸ƒ
        if len(sizes) > 0:
            ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
            ax1.set_title('æŸä¼¤ç±»åž‹åˆ†å¸ƒ')
        
        # æŸ±çŠ¶å›¾ - ç½®ä¿¡åº¦åˆ†å¸ƒ
        if len(confidences) > 0:
            confidence_ranges = [0.2, 0.4, 0.6, 0.8, 1.0]
            confidence_counts = [np.sum((confidences >= low) & (confidences < high)) 
                               for low, high in zip([0.0] + confidence_ranges[:-1], confidence_ranges)]
            
            ax2.bar(['0.0-0.2', '0.2-0.4', '0.4-0.6', '0.6-0.8', '0.8-1.0'], confidence_counts, 
                   color=['red', 'orange', 'yellow', 'lightgreen', 'green'])
            ax2.set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
            ax2.set_ylabel('ç›®æ ‡æ•°é‡')
            ax2.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        chart_path = self.output_dir / f"stats_{image_name}.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return str(chart_path)
    
    def process_directory(self, directory_path, conf_threshold=0.25):
        """
        å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ
        
        Args:
            directory_path: åŒ…å«å›¾åƒçš„ç›®å½•è·¯å¾„
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        directory = Path(directory_path)
        if not directory.exists():
            raise FileNotFoundError(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        image_files = [f for f in directory.iterdir() if f.suffix.lower() in image_extensions]
        
        if not image_files:
            print(f"âš ï¸ åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {directory_path}")
            return
        
        print(f"ðŸ“ å‘çŽ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        results = []
        for i, image_file in enumerate(image_files, 1):
            print(f"\n--- å¤„ç†ç¬¬ {i}/{len(image_files)} å¼ å›¾åƒ: {image_file.name} ---")
            try:
                result_path, stats_path = self.process_image(str(image_file), conf_threshold)
                results.append((str(image_file), result_path, stats_path))
            except Exception as e:
                print(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_file}: {e}")
                results.append((str(image_file), None, None))
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        self._generate_report(results, directory_path)
        
        return results
    
    def _generate_report(self, results, source_path):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        report_path = self.output_dir / "inference_report.txt"
        
        successful = sum(1 for _, result_path, _ in results if result_path is not None)
        failed = len(results) - successful
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("YOLOv8æŸä¼¤æ£€æµ‹æŽ¨ç†æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"æºè·¯å¾„: {source_path}\n")
            f.write(f"å¤„ç†æ—¶é—´: {np.datetime64('now')}\n")
            f.write(f"æ€»å›¾åƒæ•°: {len(results)}\n")
            f.write(f"æˆåŠŸå¤„ç†: {successful}\n")
            f.write(f"å¤„ç†å¤±è´¥: {failed}\n\n")
            
            f.write("è¯¦ç»†ç»“æžœ:\n")
            f.write("-" * 50 + "\n")
            for input_path, result_path, stats_path in results:
                f.write(f"è¾“å…¥: {Path(input_path).name}\n")
                f.write(f"ç»“æžœ: {Path(result_path).name if result_path else 'å¤±è´¥'}\n")
                f.write(f"ç»Ÿè®¡: {Path(stats_path).name if stats_path else 'æ— '}\n")
                f.write("-" * 30 + "\n")
        
        print(f"ðŸ“„ å¤„ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv8æŸä¼¤æ£€æµ‹æŽ¨ç†è„šæœ¬')
    parser.add_argument('--image', type=str, required=True, 
                       help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--model', type=str, default='trained_model/yolov8n-seg-1024/weights/best.pt',
                       help='æ¨¡åž‹æƒé‡è·¯å¾„ (é»˜è®¤: trained_model/yolov8n-seg-1024/weights/best.pt)')
    parser.add_argument('--output', type=str, default='inference_results',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: inference_results)')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤: 0.25)')
    parser.add_argument('--dir', type=str, 
                       help='å¤„ç†æ•´ä¸ªç›®å½•è€Œä¸æ˜¯å•å¼ å›¾åƒ')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ£€æµ‹å™¨å®žä¾‹
        detector = DamageDetector(args.model, args.output)
        
        if args.dir:
            # å¤„ç†æ•´ä¸ªç›®å½•
            print(f"ðŸ“ å¼€å§‹å¤„ç†ç›®å½•: {args.dir}")
            detector.process_directory(args.dir, args.conf)
        else:
            # å¤„ç†å•å¼ å›¾åƒ
            result_path, stats_path = detector.process_image(args.image, args.conf)
            
            print("\n" + "="*50)
            print("ðŸŽ‰ å¤„ç†å®Œæˆ!")
            print(f"ðŸ“ ç»“æžœå›¾åƒ: {result_path}")
            if stats_path:
                print(f"ðŸ“Š ç»Ÿè®¡å›¾è¡¨: {stats_path}")
            print("="*50)
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    # å¦‚æžœç›´æŽ¥è¿è¡Œè„šæœ¬ï¼Œæ˜¾ç¤ºä½¿ç”¨è¯´æ˜Ž
    if len(os.sys.argv) == 1:
        print("""
YOLOv8æŸä¼¤æ£€æµ‹æŽ¨ç†å·¥å…·
ä½¿ç”¨æ–¹æ³•:
    
1. æ£€æµ‹å•å¼ å›¾åƒ:
   python inference.py --image å›¾ç‰‡è·¯å¾„.jpg
    
2. æ£€æµ‹ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ:
   python inference.py --dir å›¾ç‰‡ç›®å½•è·¯å¾„
    
3. ä½¿ç”¨è‡ªå®šä¹‰æ¨¡åž‹å’Œå‚æ•°:
   python inference.py --image å›¾ç‰‡è·¯å¾„.jpg --model æ¨¡åž‹è·¯å¾„.pt --conf 0.3
    
4. æŸ¥çœ‹æ‰€æœ‰å‚æ•°:
   python inference.py --help

ç¤ºä¾‹:
   python inference.py --image test_image.jpg
   python inference.py --dir ./test_images --conf 0.3
        """)
    else:
        exit(main())
